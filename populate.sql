INSERT INTO "public"."response_descriptive_coding" ("participant_id", "question_id", "original_response", "invivo_codes", "descriptive_ids") VALUES
(9, 'QQ0', 'Pretty frequently', 'Pretty frequently', 'use_daily'),
(9, 'QQ1', 'I use them mostly as code reviewers or searching something faster', 'code reviewers, searching something faster', 'code_review, research'),
(9, 'QQ2', 'I use them for code reviewing and search', 'code reviewing, search', 'code_review, research'),
(9, 'QQ3', 'I code it myself based on it output', 'code it myself based on it output', 'combining_reference'),
(9, 'QQ4', 'They made me work way faster', 'made me work way faster', 'changes_speed_improvement'),
(9, 'QQ5', 'almost never', 'almost never', 'mundane_tasks_infrequent'),
(9, 'QQ6', 'It makes it faster to code', 'faster to code', 'changes_speed_improvement'),
(9, 'QQ7', 'Bug fixing and code reviewing', 'Bug fixing, code reviewing', 'code_review, bug_fixing'),
(9, 'QQ8', 'Low memory', 'Low memory', 'small_memory_context'),
(9, 'QQ9', 'Yes, they normally make errors, but I search them up or use the LLM or fix it myself', 'make errors, use the LLM, fix it myself', 'output_errors, manual_intervention, llm_intervention'),
(9, 'QQ10', 'Being able to make it check errors without sending the code it sent to me', 'make it check errors', 'automatic_error_detection'),
(9, 'QQ11', 'Evolving more as a sub LLM like plugins', 'sub LLM like plugins', 'forecast_extension'),
(16, 'QQ0', 'Daily', 'Daily', 'use_daily'),
(16, 'QQ1', 'A lot', 'A lot', 'full_integration'),
(16, 'QQ2', 'Information gathering, solution proposal, bug fixing', 'Information gathering, solution proposal, bug fixing', 'research, conceptual_use, bug_fixing'),
(16, 'QQ3', 'Either copy pasting or adapting it into my codebase', 'copy pasting, adapting it into my codebase', 'direct_use, modified_use'),
(16, 'QQ4', 'Bug fixing and research time have been reduced', 'Bug fixing , research time reduced', 'changes_speed_improvement'),
(16, 'QQ5', 'A few times per week', 'A few times per week', 'mundane_tasks_frequent'),
(16, 'QQ6', 'It helps me to show some frameworks/modules which I didn''t know existed before', 'show some frameworks/modules', 'research'),
(16, 'QQ7', 'Framework/module search', 'Framework/module search', 'reserach'),
(16, 'QQ8', 'Their knowledge base sometimes relies on outdated information', 'outdated information', 'knowledge_cutoff'),
(16, 'QQ9', 'It sometimes introduced me a framework where it uses deprecated code', ' it uses deprecated code', 'knowledge_cutoff, output_errors'),
(16, 'QQ10', 'A more up-to-date knowledge base', 'more up-to-date knowledge', 'knowledge_update'),
(16, 'QQ11', 'They will probably more intergrated into our daily lives and have a better knowledge base', 'more intergrated, better knowledge base', 'forecast_knowledge, forecast_integration'),
(17, 'QQ0', 'Daily', 'Daily', 'use_daily'),
(17, 'QQ1', 'I use them in my IDEs', 'in my IDEs', 'full_integration'),
(17, 'QQ2', 'To understand new technologies, do repetitive changes, prototype, improve readability of the code.', 'understand new technologies, do repetitive changes, prototype, improve readability of the code', 'learning_use, mundane_tasks_always, code_review'),
(17, 'QQ3', 'I try to give the LLM all the context necessary for it to understand the isolated problem inside the codebase, however, I find that too much context hurts the final result.', 'too much context hurts result', 'output_errors'),
(17, 'QQ4', 'Makes my workflow faster as I am able to prototype/iterate easier', 'workflow faster, prototype/iterate easier', 'changes_speed_improvement'),
(17, 'QQ5', 'Almost everytime I need to make such changes', 'Almost everytime', 'mundane_tasks_always'),
(17, 'QQ6', 'Ease of access to information is the biggest benefit for me.', 'Ease of access to information', 'research'),
(17, 'QQ7', 'Prototyping and understanding new technologies (that I haven’t worked with)', 'Prototyping, understanding new technologies', 'learning_use, prototyping_use'),
(17, 'QQ8', 'The context windows are way too small for large medium to large sized codebases', 'context windows are way too small', 'small_memory_context'),
(17, 'QQ9', 'Yes, the tolls are not as mature as people tend to think they are. They easily hallucinate and get things wrong.', 'They easily hallucinate, get things wrong', 'output_errors'),
(17, 'QQ10', 'Better at digesting a lot of context, smarter overall.', 'Better at digesting a lot of context, smarter overall', 'improved_context, smarter_ai'),
(17, 'QQ11', 'I think Software Engineers will slowly transition more towards a Systems Engineering type or role. So, to answer the question, in the next few years I see these these tools getting more and more mature and smarter', 'tools getting more mature and smarter', 'smarter_ai'),
(18, 'QQ0', 'Daily', 'Daily', 'use_daily'),
(18, 'QQ1', 'They are built-in on the software that needs them.', 'built-in', 'full_integration'),
(18, 'QQ2', 'To generate obvious small code snippets faster. I believe that LLMs currently cannot deal with more complex code.', 'generate small code snippets', 'scope_snippet'),
(18, 'QQ3', 'Small snippets of code are integrated in the codebase, but always subject to manual review.', 'Small snippets subject to manual review', 'modified_use, manual_intervention'),
(18, 'QQ4', 'Make implementation a little faster.', 'implementation faster', 'changes_speed_improvement'),
(18, 'QQ5', 'On a weekly basis.', 'On a weekly basis', 'mundane_tasks_infrequent'),
(18, 'QQ6', 'They sometimes make the process faster.', 'make the process faster', 'changes_speed_improvement'),
(18, 'QQ7', 'Do deal with obvious tasks faster.', 'Do obvious tasks faster', 'changes_speed_improvement'),
(18, 'QQ8', 'Not being able to handle non-obvious tasks correctly / making mistakes.', 'Not handle non-obvious tasks correctly', 'output_errors'),
(18, 'QQ9', 'Running out of memory context and copy pasting code given as context.', 'Running out of memory context, copy pasting code given as context', 'small_memory_context, manual_intervention'),
(18, 'QQ10', 'Better context handling.', 'context handling', 'improved_context'),
(18, 'QQ11', 'I imagine they will begin to stabilize and keep facing the same problems.', 'stabilize, keep facing the same problems', 'forecast_plateau'),
(19, 'QQ0', 'Almost everyday.', 'Almost everyday', 'use_very_frequent'),
(19, 'QQ1', 'Officially they are not integrated because the company doesn''t specify which to use. But normally for asking questions or fixing code where we know where the problem is but I want to increase development speed.', 'not integrated, the company doesn''t specify which to use, asking questions, fixing code where we know where the problem', 'partial_integration'),
(19, 'QQ2', 'Normally to fix small bits of code or improve readability. Also for architecture questions or possible solutions to the problem.', 'Normally to fix small bits of code, improve readability, architecture questions, possible solutions to the problem', 'bug_fixing, code_review, planning_use, conceptual_use'),
(19, 'QQ3', 'We do no have integrated LLM in our IDEs like Copilot.', 'We do no have integrated LLM', 'partial_integration, output_errors'),
(23, 'QQ0', 'Often', 'Often', 'use_frequent'),
(19, 'QQ4', 'They have increased development speed and quality but sometimes that have made the development experience worse because they often give wrong or bad answers.', 'increased development speed and quality, made the development experience worse, they often give wrong or bad answers.', 'changes_speed_improvement, output_errors'),
(19, 'QQ5', 'For class generation almost everyday. Name refactoring is a bad task for LLMs given that the refactoring names are considerably worse', 'For class generation almost everyday, name refactoring is a bad task for LLMs', 'mundane_tasks_frequent'),
(19, 'QQ6', 'Increased speed, separation of concerns', 'Increased speed, separation of concerns', 'changes_speed_improvement, improved_code_quality'),
(19, 'QQ7', 'Fixing classes or small bugs', 'Fixing classes, small bugs', 'bug_fixing'),
(19, 'QQ8', 'Bad/wrong answers. LLMs sometimes don''t understand and give completely crazy answers', 'wrong answers, LLMs sometimes don''t understand, give completely crazy answers', 'output_errors'),
(19, 'QQ9', 'Yes. LLMs have trouble in counting entries, they can give you code with bad spelling', 'LLMs have trouble in counting entries, give you code with bad spelling', 'output_errors'),
(19, 'QQ10', 'LLMs should store context for at least 30 prompts unless the user says to forget it. They should be able to do more mundane tasks.', 'LLMs should store context, unless the user says to forget it, do more mundane tasks.', 'improved_context, forecast_integration'),
(19, 'QQ11', 'I believe Software Development will transition to IDEs(IntelliJ, Visual Studio) using agents like Copilot. The AI tools will become better and more focused on solving problems instead of giving suggestions.', ' will transition to IDEs using agents. The AI tools will become better, more focused on solving problems instead of giving suggestions.', 'smarter_ai, forecast_integration'),
(20, 'QQ0', 'often', 'often', 'use_frequent'),
(20, 'QQ1', 'part of it', 'part of it', 'partial_integration'),
(20, 'QQ2', 'architectural decisions implications SWOT analisys', 'architectural decisions, implications, SWOT analysis', 'planning_use, conceptual_use, documentation_use'),
(20, 'QQ3', 'agent mode and context', 'agent mode, context', 'improved_context'),
(20, 'QQ4', 'faster execution, better documentation', 'faster execution, better documentation', 'changes_speed_improvement, improved_documentation'),
(20, 'QQ5', 'as much as possible with carefull review. atomic changes every time', 'as much as possible, carefull review. atomic changes every time', 'mundane_tasks_always, modified_use, scope_snippet'),
(20, 'QQ6', 'faster cide writing', 'faster code writing', 'changes_speed_improvement'),
(20, 'QQ7', 'refactoring and migration of models', 'refactoring, migration of models', 'code_review'),
(20, 'QQ8', 'context loss', 'context loss', 'small_memory_context'),
(20, 'QQ9', 'a lot of times since simple typings all the way up to business logic', 'a lot of times, simple typings,  all the way up to business logic', 'output_errors'),
(20, 'QQ10', 'better bigger context and awareness', 'bigger context and awareness', 'improved_context'),
(20, 'QQ11', 'mind of their not based on copy pasted code', 'mind of their own', 'smarter_ai'),
(21, 'QQ0', 'Often', 'Often', 'use_very_frequent'),
(21, 'QQ1', 'Very much', 'Very much', 'full_integration'),
(21, 'QQ2', 'I basically use LLMs in order to write code or to find bugs in already existing codes.', 'LLMs in order to write code, find bugs', 'prototyping_use, bug_fixing, code_review'),
(21, 'QQ3', 'I treat LLM-generated code as a starting template rather than final production code. I first review it to ensure it fits our coding style, architecture, and naming conventions. Then, I test it locally, refactor where needed, and integrate it gradually into the codebase. I also run static analysis, unit tests, and peer review to catch any hidden issues. In short, I use the model for speed, but I always validate and adapt the code before merging it.', ' LLM-generated code as a template, review it, test it locally, refactor, and integrate, peer review,  use for speed, but  validate and adapt the code', 'modified_use, manual_intervention'),
(21, 'QQ4', 'They have sped up initial implementation steps, reduced time spent searching documentation, and allowed me to prototype ideas faster. My workflow has shifted to a more iterative approach where I ask for suggestions, refine them, and integrate selectively instead of writing everything from scratch.', 'sped up implementation, reduced time spent searching documentation, prototype ideas faster. more iterative approach, ask for suggestions, refine them, integrate selectively', 'changes_speed_improvement, prototyping_use'),
(21, 'QQ5', 'Every day', 'Every day', 'mundane_tasks_always'),
(21, 'QQ6', 'I’ve experienced several benefits when using LLMs in my development workflow. They significantly reduce the time I spend on repetitive or boilerplate tasks, allowing me to focus on more complex and creative problem-solving. They also help me quickly understand unfamiliar code or technologies by providing concise explanations and examples. Additionally, LLMs improve productivity by offering alternative implementations, suggesting best practices, and helping me catch small issues earlier through code review assistance. Overall, they make the development process faster, smoother, and more efficient.', 'reduce the time on repetitive tasks, allowing me to focus on problem-solving. help me understand unfamiliar code or technologie, review assistance. development process faster, smoother, more efficient.', 'changes_speed_improvement, learning_use, research, code_review'),
(21, 'QQ7', 'I find LLMs most helpful when I need quick guidance or examples during development, such as generating boilerplate code, explaining unfamiliar libraries, or converting code between languages. They are also useful for summarizing documentation, debugging error messages, and brainstorming solutions during the early design phase of a feature.', 'I find LLMs most helpful when I need quick guidance or examples during development, such as generating boilerplate code, explaining unfamiliar libraries, or converting code between languages. They are also useful for summarizing documentation, debugging error messages, and brainstorming solutions during the early design phase of a feature.', 'learning_use, reserach, bug_fixing'),
(21, 'QQ8', 'A common frustration is that LLMs sometimes produce code that looks correct but contains subtle logical errors or assumptions that don’t fit the context. They also occasionally hallucinate functions or APIs that don’t exist. Additionally, getting consistent output requires well-structured prompts, which can be time-consuming.', 'A common frustration is that LLMs sometimes produce code that looks correct but contains subtle logical errors or assumptions that don’t fit the context. They also occasionally hallucinate functions or APIs that don’t exist. Additionally, getting consistent output requires well-structured prompts, which can be time-consuming.', 'output_errors, query_time_consuming'),
(23, 'QQ1', 'A lot', 'A lot', 'full_integration'),
(23, 'QQ2', 'I treat LLMs as a productivity amplifier: they speed up repetitive tasks', 'productivity amplifier, speed up repetitive tasks', 'mundane_tasks_always'),
(1, 'QQ0', 'Everyday', 'Everyday', 'use_daily'),
(4, 'QQ10', 'N/A', 'N/A', 'N/A'),
(21, 'QQ9', 'Yes. For example, when generating code for a backend service, the model included pseudo-functions from an older library version, causing runtime errors. There were also cases where generated code introduced hidden performance issues or lacked proper error handling, which required manual review and refactoring.', 'Yes. For example, when generating code for a backend service, the model included pseudo-functions from an older library version, causing runtime errors. There were also cases where generated code introduced hidden performance issues or lacked proper error handling, which required manual review and refactoring.', 'knowledge_cutoff, output_errors, manual_intervention'),
(21, 'QQ10', 'I''d like stronger context awareness and the ability to integrate more deeply with my actual project files, not just pasted snippets. Improvements in reasoning, especially around architecture and edge cases, would be helpful. Also, having a clearer confidence indicator or warnings when the model is uncertain would reduce mistakes.', 'I''d like stronger context awareness and the ability to integrate more deeply with my actual project files, not just pasted snippets. Improvements in reasoning, especially around architecture and edge cases, would be helpful. Also, having a clearer confidence indicator or warnings when the model is uncertain would reduce mistakes.', 'improved_context, smarter_ai, better_integration, certainity_indicators'),
(21, 'QQ11', 'I imagine AI tools will become more deeply integrated into the development workflow. Instead of interacting with them through chat prompts, they will likely operate directly inside our IDEs, understanding our entire codebase, project structure, and business logic. They will act more like intelligent collaborators—able to propose architectural designs, detect potential bugs before they occur, and automate larger parts of the development lifecycle. However, I still expect human engineers to guide decision-making, ensure code quality, and handle complex problem-solving, while AI accelerates routine tasks and reduces cognitive load.', 'I imagine AI tools will become more deeply integrated into the development workflow. Instead of interacting with them through chat prompts, they will likely operate directly inside our IDEs, understanding our entire codebase, project structure, and business logic. They will act more like intelligent collaborators—able to propose architectural designs, detect potential bugs before they occur, and automate larger parts of the development lifecycle. However, I still expect human engineers to guide decision-making, ensure code quality, and handle complex problem-solving, while AI accelerates routine tasks and reduces cognitive load.', 'forecast_intergration, forecast_smarter_ai'),
(22, 'QQ0', 'increasingly often', 'increasingly often', 'use_frequent'),
(22, 'QQ1', 'Quite often', 'Quite often', 'moderate_integration'),
(22, 'QQ2', 'I typically use LLMs to write code, fix bugs, draft documents and documentation, and organize and analyze data.', 'I typically use LLMs to write code, fix bugs, draft documents and documentation, and organize and analyze data', 'prototyping_use, bug_fixing, documentation_use, data_analysis_use'),
(22, 'QQ3', 'I review and test the generated code carefully to ensure it fits well with the existing codebase. I integrate it incrementally, verifying functionality and maintaining code quality. Proper documentation and refactoring help keep the codebase consistent and manageable.', 'I review and test the generated code carefully to ensure it fits well with the existing codebase. I integrate it incrementally, verifying functionality and maintaining code quality. Proper documentation and refactoring help keep the codebase consistent and manageable', 'modified_use'),
(22, 'QQ4', 'LLMs have streamlined repetitive tasks, helped me write and debug code faster, improved documentation, and allowed me to focus more on complex problems and creative solutions. They have significantly increased my productivity and made collaboration easier', 'LLMs have streamlined repetitive tasks, helped me write and debug code faster, improved documentation, and allowed me to focus more on complex problems and creative solutions. They have significantly increased my productivity and made collaboration easier', 'changes_speed_improvement, improved_documentation'),
(22, 'QQ5', 'I use LLMs quite often', 'I use LLMs quite often', 'mundane_tasks_frequent'),
(22, 'QQ6', 'Using LLMs has significantly improved my productivity by automating routine coding tasks, enhancing code quality through instant reviews, and speeding up documentation. It also enables me to focus more on complex problems and creative solutions.', 'improved productivity, automating coding, instant reviews,, speeding up documentation, enables me to focus more on complex problems and creative solutions', 'improved_code_quality, changes_speed_improvement, code_review, improved_documentation'),
(22, 'QQ7', 'I find LLMs most helpful for automating repetitive coding tasks, generating and refactoring code, writing and updating documentation, and quickly analyzing or summarizing large amounts of data and also in debugging', ' automating tasks, generating code, writing documentation, analyzing data, debugging', 'mundane_tasks_frequent, improved_documentation, data_analysis_use, bug_fixing'),
(22, 'QQ8', 'I sometimes face challenges such as inconsistent or unpredictable responses from LLMs. They can generate incorrect or biased information, which requires careful review. Also, high computational costs and integration complexity can be frustrating.', ' inconsistent or unpredictable responses, generate incorrect or biased information, careful review, high computational costs, integration complexity can be frustrating.', 'output_errors, manual_intervention, poor_integration, high_computation_cost'),
(22, 'QQ9', 'I have encountered challenges such as occasional incorrect or biased outputs from LLMs, which require careful validation. There can be issues with logic and reasoning, and sometimes high computational costs cause delays. These problems mean that human oversight remains essential when using these tools.', ' incorrect or biased outputs, careful validation, issues with logic and reasoning, high computational costs. human oversight essential', 'output_errors, manual_intervention, high_computation_cost'),
(22, 'QQ10', 'I would like to see LLMs become more accurate and reliable, with better real-time fact-checking capabilities. Improvements in understanding complex contexts and long-term memory would be valuable. Additionally, reducing computational costs and enhancing integration with existing development tools would make them more practical for daily use.', 'more accurate and reliable, better real-time fact-checking. Improvements in understanding, long-term memory would be valuable. reducing computational costs, enhancing integration', 'automatic_error_detection, smarter_ai, improved_context, better integration, lower_computation_cost'),
(22, 'QQ11', 'I imagine AI tools becoming more autonomous and integrated, capable of handling complex tasks with minimal human intervention. They will improve in understanding context, maintaining long-term memory, and collaborating seamlessly with human developers. Additionally, AI will become more accessible, efficient, and specialized for different development needs, transforming software engineering workflows significant', 'more autonomous and integrated, handling complex tasks, minimal human intervention, understanding context, maintaining long-term memory, collaborating with developers, more accessible, efficient, specialized', 'forecast_smarter_ai, forecast_knowledge, forecast_integration'),
(23, 'QQ3', 'I use LLM-generated code as a starting point, not a final product.', 'LLM-generated code as a starting point', 'modified_use, combining_reference'),
(23, 'QQ4', 'LLMs have made my workflow faster and more efficient.', 'workflow faster and more efficient', 'changes_speed_improvement'),
(23, 'QQ5', 'A lot', 'A lot', 'mundane_tasks_always'),
(23, 'QQ6', 'LLMs save me time by automating repetitive tasks and generating boilerplate code.', 'automating repetitive tasks, generating boilerplate code', 'mundane_tasks_always'),
(23, 'QQ7', 'LLMs are most helpful for writing documentation or summarizing code, which saves time on repetitive tasks.', 'writing documentation, summarizing code, saves time on repetitive tasks', 'documentation_use, reserach'),
(23, 'QQ8', 'Sometimes LLMs produce incorrect or incomplete code, suggest inefficient solutions, or rely on unfamiliar libraries.', 'incorrect or incomplete code, suggest inefficient solutions, rely on unfamiliar libraries', 'output_errors'),
(23, 'QQ9', 'LLMs sometimes generate code with bugs, logical errors, or security issues.', 'generate code with bugs, logical errors, or security issues', 'output_errors'),
(23, 'QQ10', 'I’d like future LLMs to provide better context awareness of existing codebases, generate more reliable and efficient code, and integrate seamlessly with development tools and version control.', 'better context awareness, generate more reliable code, and integrate seamlessly with development tools', 'better_integration, improved_context, smarter_ai'),
(23, 'QQ11', 'I expect AI tools to become more context-aware, assist with full-stack development, automate testing and refactoring, and integrate deeply with IDEs and team workflows.', 'more context-aware, assist with full-stack development, automate testing and refactoring, and integrate with IDEs and team workflows', 'forecast_knowledge, forecast_integration'),
(10, 'Q0', 'Daily', 'Daily', 'use_daily'),
(10, 'Q1', 'Moderately, manual work to fully take advantage is still nedded', 'Moderately, manual work to fully take advantage is still nedded', 'moderate_integration'),
(10, 'Q2', 'Implement well defined code blocks; explain code logic', 'Implement well defined code blocks; explain code logic', 'learning_use, prototyping_use'),
(10, 'QQ0', 'Daily', 'Daily', 'use_daily'),
(10, 'QQ1', 'Moderately, manual work to fully take advantage is still nedded', 'Moderately, manual work to fully take advantage is still nedded', 'moderate_integration'),
(10, 'QQ2', 'Implement well defined code blocks; explain code logic', 'Implement well defined code blocks; explain code logic', 'learning_use, prototyping_use'),
(10, 'QQ3', 'Generate and review the generated work', 'Generate and review the generated work', 'combining_reference'),
(10, 'QQ4', 'Less time wasted on millennial tasks', 'Less time wasted on millennial tasks', 'changes_speed_improvement'),
(10, 'QQ5', 'Whenever that work comes up', 'Whenever that work comes up', 'mundane_tasks_always'),
(10, 'QQ6', 'Less tedious work', 'Less tedious work', 'changes_speed_improvement'),
(10, 'QQ7', 'Generate code from well defined specs', 'Generate code from well defined specs', 'prototyping_use'),
(10, 'QQ8', 'Low prompt adherence for longer prompts', 'Low prompt adherence for longer prompts', 'small_memory_context'),
(10, 'QQ9', 'Low prompt adherence for longer prompts; limited usage/high costs', 'Low prompt adherence for longer prompts; limited usage/high costs', 'small_memory_context, high_computation_cost'),
(10, 'QQ10', 'Better overall, and more autonomous', 'Better overall, and more autonomous', 'smarter_ai'),
(10, 'QQ11', 'Becoming More and more useful', 'Becoming More and more useful', 'forecast_smarter_ai'),
(11, 'QQ0', 'Daily', 'Daily', 'use_daily'),
(11, 'QQ1', 'These tools are deeply integrated into my workflow. I use them routinely when planning tasks, fixing bugs, and developing new features. They are not just occasional aids but fundamental tools that complement my coding process.', 'These tools are deeply integrated into my workflow. I use them routinely when planning tasks, fixing bugs, and developing new features. They are not just occasional aids but fundamental tools that complement my coding process.', 'full_integration'),
(11, 'QQ2', 'I utilize LLMs to assist in issue planning, code generation, debugging, and feature development. For example, I often use tools like Cursor and GitHub Copilot to get relevant code suggestions and for indexing and understanding my codebase to improve suggestion accuracy. When the suggestions are inaccurate, I tag specific files to provide better context to the model.', 'I utilize LLMs to assist in issue planning, code generation, debugging, and feature development. For example, I often use tools like Cursor and GitHub Copilot to get relevant code suggestions and for indexing and understanding my codebase to improve suggestion accuracy. When the suggestions are inaccurate, I tag specific files to provide better context to the model.', 'planning_use, prototyping_use, documentation_use, code_review'),
(11, 'QQ3', 'I carefully review and sometimes modify the generated code to ensure it fits the architecture and coding standards of my project. I integrate the code by testing it thoroughly and merging it only after confirming it doesn’t introduce bugs or inconsistencies.', 'I carefully review and sometimes modify the generated code to ensure it fits the architecture and coding standards of my project. I integrate the code by testing it thoroughly and merging it only after confirming it doesn’t introduce bugs or inconsistencies.', 'modified_use, combining_reference'),
(11, 'QQ4', 'LLMs have made my workflow more efficient and less error-prone. They reduce the time spent on mundane coding tasks, speed up debugging, and help me generate boilerplate or complex code quickly. This allows me to focus more on design and higher-level problem solving.', 'LLMs have made my workflow more efficient and less error-prone. They reduce the time spent on mundane coding tasks, speed up debugging, and help me generate boilerplate or complex code quickly. This allows me to focus more on design and higher-level problem solving.', 'changes_speed_improvement, improved_code_quality'),
(11, 'QQ5', 'I use LLMs regularly for these mundane tasks. They are invaluable for repetitive code refactoring, generating classes, and cleaning code comments, which saves a lot of time that I would otherwise spend on manual edits.', 'I use LLMs regularly for these mundane tasks. They are invaluable for repetitive code refactoring, generating classes, and cleaning code comments, which saves a lot of time that I would otherwise spend on manual edits.', 'mundane_tasks_frequent'),
(11, 'QQ6', 'The main benefits include faster development cycles, higher code quality due to reduced human errors, improved creativity with suggestions for new approaches, and less cognitive load for repetitive tasks. They also help me stay consistent with best practices.', 'The main benefits include faster development cycles, higher code quality due to reduced human errors, improved creativity with suggestions for new approaches, and less cognitive load for repetitive tasks. They also help me stay consistent with best practices.', 'changes_speed_improvement, improved_code_quality'),
(1, 'QQ1', 'Very much so. In all tools almost', 'In all tools almost', 'full_integration'),
(5, 'QQ11', 'N/A', 'N/A', 'N/A'),
(11, 'QQ7', 'LLMs are most helpful during task planning, writing new feature code, fixing bugs, and generating boilerplate code or documentation. They are particularly useful when working on unfamiliar parts of the codebase or when under time constraints.', 'LLMs are most helpful during task planning, writing new feature code, fixing bugs, and generating boilerplate code or documentation. They are particularly useful when working on unfamiliar parts of the codebase or when under time constraints.', 'planning_use, prototyping_use, bug_fixing, learning_use'),
(11, 'QQ8', 'Sometimes the suggestions from LLMs are inaccurate, out of context, or do not adhere to project-specific conventions. There can also be occasional misunderstandings of complex requirements, and the need to verify all generated code can slightly slow down the process.', 'Sometimes the suggestions from LLMs are inaccurate, out of context, or do not adhere to project-specific conventions. There can also be occasional misunderstandings of complex requirements, and the need to verify all generated code can slightly slow down the process.', 'output_errors, knowledge_cutoff, query_time_consuming'),
(11, 'QQ9', 'Yes, occasionally LLMs produce code that introduces bugs or doesn’t integrate cleanly with the existing codebase, requiring me to debug or rewrite parts of the suggestions. Sometimes, they generate incorrect logic or overlook edge cases. One example is that they don''t know what it is a GUID...', 'Yes, occasionally LLMs produce code that introduces bugs or doesn’t integrate cleanly with the existing codebase, requiring me to debug or rewrite parts of the suggestions. Sometimes, they generate incorrect logic or overlook edge cases. One example is that they don''t know what it is a GUID...', 'output_errors, knowledge_cutoff, manual_intervention'),
(11, 'QQ10', 'Enhanced feedback mechanisms and more offline capabilities would also be useful.', 'Enhanced feedback mechanisms and more offline capabilities would also be useful.', 'certainty_indicators, lower_computation_cost'),
(11, 'QQ11', 'I foresee AI tools becoming more collaborative partners that understand entire projects contextually, help with design decisions, automate testing and deployment, and provide real-time code quality and security insights. They may evolve to handle higher-level planning and architectural guidance, making software engineering more efficient and innovative.', 'I foresee AI tools becoming more collaborative partners that understand entire projects contextually, help with design decisions, automate testing and deployment, and provide real-time code quality and security insights. They may evolve to handle higher-level planning and architectural guidance, making software engineering more efficient and innovative.', 'forecast_smarter_ai, forecast_knowledge, forecast_integration'),
(12, 'QQ0', 'Depends on the task that I am doing but I would say I use it most days.', 'Depends on the task that I am doing but I would say I use it most days.', 'use_very_frequent'),
(12, 'QQ1', 'Not much, I try to use them only when necessary.', 'Not much, I try to use them only when necessary.', 'partial_integration'),
(12, 'QQ2', 'I use LLMs mainly for debugging and weird errors that I am not understanding so, normally I just copy the error, give it a bit of context about the technology that I am using and then paste in the error.', 'I use LLMs mainly for debugging and weird errors that I am not understanding so, normally I just copy the error, give it a bit of context about the technology that I am using and then paste in the error.', 'bug_fixing, learning_use, research'),
(12, 'QQ3', 'I treat LLM generated code as a suggestion. I review it, adapt it to fit my existing codebase, and make any necessary adjustments to ensure consistency and reliability.', 'I treat LLM generated code as a suggestion. I review it, adapt it to fit my existing codebase, and make any necessary adjustments to ensure consistency and reliability.', 'modified_use, combining_reference'),
(12, 'QQ4', 'It has certainly accelerated the code development process and debugging, however it feels like, the more I use it, the more dependent I become so I try to use them only when necessary.', 'It has certainly accelerated the code development process and debugging, however it feels like, the more I use it, the more dependent I become so I try to use them only when necessary.', 'changes_speed_improvement'),
(12, 'QQ5', 'Not much, I normally depend on IDE tools for these tasks.', 'Not much, I normally depend on IDE tools for these tasks.', 'mundane_tasks_infrequent'),
(12, 'QQ6', 'I find that I write code much faster than without it.', 'I find that I write code much faster than without it.', 'changes_speed_improvement'),
(12, 'QQ7', 'I find them most helpful when I am dealing with some new technology or when I am doing something that I have never done before.', 'I find them most helpful when I am dealing with some new technology or when I am doing something that I have never done before.', 'learning_use'),
(12, 'QQ8', 'One challenge I often face when using LLMs is the amount of context I need to provide for certain problems. Without sufficient background information, the model’s responses can become too generic or miss key details.', 'One challenge I often face when using LLMs is the amount of context I need to provide for certain problems. Without sufficient background information, the model’s responses can become too generic or miss key details.', 'output_errors, query_time_consuming'),
(12, 'QQ9', 'Yes, quite a few. Most issues occur when the model doesn’t have enough context, which is especially problematic in larger projects where details matter.', 'Yes, quite a few. Most issues occur when the model doesn’t have enough context, which is especially problematic in larger projects where details matter.', 'small_memory_context, output_errors, manual_intervention'),
(12, 'QQ10', 'I’m not entirely sure, but I think improvements that help LLMs better understand complex project contexts or maintain continuity across sessions would be really useful.', 'I’m not entirely sure, but I think improvements that help LLMs better understand complex project contexts or maintain continuity across sessions would be really useful.', 'improved_context, better_integration'),
(12, 'QQ11', 'I imagine AI tools will become more deeply integrated into the development process, offering better context awareness, smarter debugging, and more personalized assistance for developers.', 'I imagine AI tools will become more deeply integrated into the development process, offering better context awareness, smarter debugging, and more personalized assistance for developers.', 'forecast_smarter_ai, forecast_knowledge, forecast_integration'),
(13, 'QQ0', 'I use LLMs throughout the day for tasks ranging from brainstorming or explaining something and debugging.', 'I use LLMs throughout the day for tasks ranging from brainstorming or explaining something and debugging.', 'use_very_frequent'),
(13, 'QQ1', 'I have it on my IDE.', 'I have it on my IDE.', 'full_integration'),
(13, 'QQ2', 'writing tests and explaining unfamiliar libraries or frameworks. They’re also invaluable for reviewing pull requests and generating documentation or comments.', 'writing tests and explaining unfamiliar libraries or frameworks. They’re also invaluable for reviewing pull requests and generating documentation or comments.', 'learning_use, code_review, documentation_use'),
(13, 'QQ3', 'I always review, test, and adjust the generated code to fit project conventions, architecture, and performance requirements before merging it.', 'I always review, test, and adjust the generated code to fit project conventions, architecture, and performance requirements before merging it.', 'modified_use, combining_reference'),
(13, 'QQ4', 'They’ve drastically reduced time spent on repetitive coding and documentation. I spend less time searching Stack Overflow or reading API docs and more time focusing on higher-level design and logic.', 'They’ve drastically reduced time spent on repetitive coding and documentation. I spend less time searching Stack Overflow or reading API docs and more time focusing on higher-level design and logic.', 'changes_speed_improvement, mundane_tasks_always'),
(13, 'QQ5', 'Very often', 'Very often', 'mundane_tasks_frequent'),
(13, 'QQ6', 'Increased productivity and faster iteration cycles, Better understanding of unfamiliar technologies, Easier onboarding for new projects', 'Increased productivity and faster iteration cycles, Better understanding of unfamiliar technologies, Easier onboarding for new projects', 'changes_speed_improvement, learning_use'),
(13, 'QQ7', 'When I need to quickly prototype features, debug tricky errors, write test cases, or generate alternative code implementations for comparison.', 'When I need to quickly prototype features, debug tricky errors, write test cases, or generate alternative code implementations for comparison.', 'prototyping_use, bug_fixing, learning_use'),
(13, 'QQ8', 'Sometimes the generated code is subtly incorrect or outdated. It can also produce overconfident answers that sound right but fail tests. Context management is another issue as it can forget earlier parts of the conversation or misunderstand project-specific constraints.', 'Sometimes the generated code is subtly incorrect or outdated. It can also produce overconfident answers that sound right but fail tests. Context management is another issue as it can forget earlier parts of the conversation or misunderstand project-specific constraints.', 'output_errors, knowledge_cutoff, small_memory_context'),
(13, 'QQ9', 'Yes. The most common issues are logical bugs introduced by generated code or minor syntax errors that pass initial review. Occasionally, the model suggests deprecated APIs or insecure implementations.', 'Yes. The most common issues are logical bugs introduced by generated code or minor syntax errors that pass initial review. Occasionally, the model suggests deprecated APIs or insecure implementations.', 'output_errors, knowledge_cutoff'),
(13, 'QQ10', 'Persistent project memory and awareness of coding style, Better test generation and automatic validation and Deeper integration with codebases.', 'Persistent project memory and awareness of coding style, Better test generation and automatic validation and Deeper integration with codebases.', 'improved_context, better_integration, smarter_ai, automatic_error_detection'),
(13, 'QQ11', 'I expect AI to become a fully embedded development partner: understanding project history, enforcing best practices, running automated reviews, and assisting in architectural decision-making.', 'I expect AI to become a fully embedded development partner: understanding project history, enforcing best practices, running automated reviews, and assisting in architectural decision-making.', 'forecast_smarter_ai, forecast_integration'),
(14, 'QQ0', 'Everyday', 'Everyday', 'use_very_frequent'),
(14, 'QQ1', 'I do a lot of researching, planning and development and I use it everywhere.', 'I do a lot of researching, planning and development and I use it everywhere.', 'full_integration'),
(14, 'QQ2', 'Whenever i delegate a task to an agent i typically pass the context of the work that needs to be done, then depending on the complexity I sometimes break the problem into several steps and i let it execute, and in case of changes i ofc review the changes.', 'Whenever i delegate a task to an agent i typically pass the context of the work that needs to be done, then depending on the complexity I sometimes break the problem into several steps and i let it execute, and in case of changes i ofc review the changes.', 'prototyping_use'),
(14, 'QQ3', 'I typically use tools that can investigate, review or change code locally, like claude code, cursor etc... so it the same normal workflow but on steroids.', 'I typically use tools that can investigate, review or change code locally, like claude code, cursor etc... so it the same normal workflow but on steroids.', 'modified_use, combining_reference, code_review'),
(14, 'QQ4', 'I can experiment and develop faster. Its more fun now.', 'I can experiment and develop faster. Its more fun now.', 'changes_speed_improvement'),
(14, 'QQ5', 'We use AI a lot for that, we normally create rules and validations points for those. Its being working good.', 'We use AI a lot for that, we normally create rules and validations points for those. Its being working good.', 'mundane_tasks_always'),
(14, 'QQ6', 'Besides speed is the time to focus on those things you have been postponing for a while, Refactoring, creating POC, more time to think on high level goals.', 'Besides speed is the time to focus on those things you have been postponing for a while, Refactoring, creating POC, more time to think on high level goals.', 'changes_speed_improvement, prototyping_use'),
(14, 'QQ7', 'As I said I use them everywhere.', 'As I said I use them everywhere.', 'research, planning_use, prototyping_use'),
(14, 'QQ8', 'Getting bad output, sometimes even for simple things.', 'Getting bad output, sometimes even for simple things.', 'output_errors'),
(14, 'QQ9', 'Besides the normal ones no. I use them as tools and most of the times is either bad context/prompting or working is a complex problem without breaking it down.', 'Besides the normal ones no. I use them as tools and most of the times is either bad context/prompting or working is a complex problem without breaking it down.', ''),
(14, 'QQ10', 'Personality, I would like it to operate just like a work colleague. Now it''s just a unshaped tool, I know there are some techniques that I can use but it should come with this adaptability skill out of the box.', 'Personality, I would like it to operate just like a work colleague. Now it''s just a unshaped tool, I know there are some techniques that I can use but it should come with this adaptability skill out of the box.', 'smarter_ai'),
(14, 'QQ11', 'Having learning skills just like us while we interact with them.', 'Having learning skills just like us while we interact with them.', 'forecast_smarter_ai'),
(15, 'QQ0', 'Frequently', 'Frequently', 'use_frequent'),
(15, 'QQ1', 'Somewhat integrated', 'Somewhat integrated', 'moderate_integration'),
(15, 'QQ2', 'about 3 to 5 times a week', 'about 3 to 5 times a week', 'use_frequent'),
(15, 'QQ3', 'I adapt the code to make sure it works exactly as intended', 'I adapt the code to make sure it works exactly as intended', 'modified_use'),
(15, 'QQ4', 'Mainly in how fast I can code, while keeping code quality.', 'Mainly in how fast I can code, while keeping code quality.', 'changes_speed_improvement, improved_code_quality'),
(15, 'QQ5', 'For those tasks i don''t use LLMs', 'For those tasks i don''t use LLMs', 'mundane_tasks_infrequent'),
(15, 'QQ6', 'Faster coding and less blocks.', 'Faster coding and less blocks.', 'changes_speed_improvement'),
(15, 'QQ7', 'in complex features to solve code blocks and ensure the feature is finished in a timely manner', 'in complex features to solve code blocks and ensure the feature is finished in a timely manner', 'bug_fixing, changes_speed_improvement'),
(15, 'QQ8', 'the ocasional LLMs allucinations that we get either by providing a vague prompt or from the models themselves.', 'the ocasional LLMs allucinations that we get either by providing a vague prompt or from the models themselves.', 'output_errors'),
(15, 'QQ9', 'I have, I have used some code snippets from the LLM and because of a minor detail the code did not work as intended and the debugging took more time that writing the code from scratch.', 'I have, I have used some code snippets from the LLM and because of a minor detail the code did not work as intended and the debugging took more time that writing the code from scratch.', 'output_errors, manual_intervention'),
(15, 'QQ10', 'context awareness and the abillity for the LLM to ask questions in order to provide the best response for the specific case.', 'context awareness and the abillity for the LLM to ask questions in order to provide the best response for the specific case.', 'improved_context, smarter_ai'),
(15, 'QQ11', 'MAinly achieving the features i mentioned on the previous question.', 'MAinly achieving the features i mentioned on the previous question.', 'forecast_smarter_ai, forecast_knowledge'),
(1, 'QQ2', 'To aid in the strategy of a solution, bug fixing and repetitive tasks', 'aid in the strategy of a solution, bug fixing, repetitive tasks', 'planning_use, bug_fixing'),
(1, 'QQ3', 'Rarely directly', 'rarely directly', 'direct_use'),
(1, 'QQ4', 'It has made it faster and more efficient', 'faster, more efficient', 'changes_speed_improvement'),
(1, 'QQ5', 'All of the above', 'name refactoring, comment removal, class generation', 'mundane_tasks_always'),
(1, 'QQ6', 'Speed mostly. It also has shown me ways to solve issues i hadn''t thought of before', 'speed, solve issues i hadn''t thought of before', 'changes_speed_improvement'),
(1, 'QQ7', 'Mundane tasks', 'mundane tasks', 'mundane_tasks_always'),
(1, 'QQ8', 'They tend to hallucinate when not dealt with correctly', 'hallucinate', 'output_errors'),
(1, 'QQ9', 'Yes, sometimes they insist on a wrong answer provided by them', 'they insist on a wrong answer', 'output_errors'),
(1, 'QQ10', 'Deminished hallucination', 'Deminished hallucination', 'output_errors'),
(1, 'QQ11', 'I imagine it becoming more and more useful for us engineers. I don''t think it can replace our jobs.', 'more useful for us engineers, I don''t think it can replace our jobs', 'forecast_smarter_ai'),
(2, 'QQ0', 'Every day', 'Daily', 'use_daily'),
(2, 'QQ1', 'Currently fully integrated', 'totally integrated', 'full_integration'),
(2, 'QQ2', 'I use LLMs mainly to assist in programming, especially for front-end tasks. I also use them to study and organize my code.', 'aid in programming, study, organize code', 'code_review'),
(2, 'QQ3', 'I usually review and test the code generated by the LLM before integrating it into my existing codebase. I tend to adapt it to match the structure and coding standards of my project.', 'revise, test generated code, adapt code', 'modified_use'),
(2, 'QQ4', 'More productivity, learning, and organization.', 'more productivity, learning outcome, organization', 'improved_workflow'),
(2, 'QQ5', 'I use LLMs quite often for this type of task. They help me save time on repetitive work.', 'quite frequently, saving time in repetitive tasks', 'mundane_tasks_frequent'),
(2, 'QQ6', 'They have greatly increased my productivity and learning.', 'increased productivity and learning', 'improved_workflow'),
(2, 'QQ7', 'For front-end and organization.', 'front-end and organization', 'code_review'),
(2, 'QQ8', 'Sometimes they hallucinate in responses, generating incorrect information or code.', 'hallucination in responses, generating incorrect information', 'output_errors'),
(2, 'QQ9', 'Yes. Sometimes the generated code contains subtle errors or does not work as expected, especially when the model does not fully understand the project context.', 'subtle code errors, code doesn''t perform as expected, llm doesn''t understand context', 'output_errors'),
(2, 'QQ10', 'Better context understanding and improvements in back-end code generation, where I still notice some limitations.', 'better context understanding', 'smarter_ai'),
(2, 'QQ11', 'I believe AI tools will become even more integrated into the development workflow, offering more accurate and contextual suggestions, and may even become partially or fully autonomous in code creation.', 'more integrated in the workflow, providing more precise suggestions, becoming autonomous in coding', 'forecast_integration'),
(3, 'QQ0', 'Daily', 'Daily', 'use_daily'),
(3, 'QQ1', 'Automatic – They are built into JetBrains products', 'automatic, built into IDE', 'full_integration'),
(3, 'QQ2', 'Autocomplete', 'autocomplete', 'scope_snippet'),
(3, 'QQ3', 'I write it myself and accept the line completions', 'write it myself, accept completions', 'scope_snippet'),
(3, 'QQ4', 'They have made me able to skip reading documentation to find the correct function in a library', 'skip reading documentation', 'improved_documentation'),
(3, 'QQ5', 'Never. I have my IDE to make sure the refactorings are done correctly and fully applied throughout the project', 'never', 'mundane_tasks_never'),
(3, 'QQ6', 'I can skip reading documentation and have the LLM suggest the correct use of a library', 'skip reading documentation, LLM suggests the correct use of a library', 'improved_documentation'),
(3, 'QQ7', 'When using a new unfamiliar language or library', 'using a new language or library', 'learning_use'),
(3, 'QQ8', 'They sometimes pull from wild sources and can''t tell me that the solution I''m working on is impractical. Trying to vibe code something that isn''t just a single batch or Python file usually fails. I can sometimes catch myself spending hours trying to get the output I want by adding more context or adjusting my prompt.', '[LLMS] pull from wild sources, can''t tell me that the solution I''m working on is impractical.vibe code that isn''t a single batch or Python file usually fails. spending hours to get the output by adding more context', 'output_errors'),
(3, 'QQ9', 'They occasionally hallucinate the function calls or parameters, their code doesn''t compile, they go on an endless explanation trail when I want code, or they provide code when I want an explanation or overview.', 'They hallucinate function calls, code doesn''t compile, endless explanation when I want code, provide code when I want an explanation', 'output_errors'),
(3, 'QQ10', 'Better integration in my IDE such that it can receive errors or variable names as it is generating code', 'Better integration in my IDE', 'better_integration'),
(7, 'QQ10', 'I think the approach that Copilot has used is great, but I would like for it to be better at detecting when its answers might not be correct', 'better at detecting when its answers might not be correct', 'smarter_ai'),
(7, 'QQ11', 'I imagine more and more usage because it can increase productivity a lot', 'more usage', 'more_usage'),
(3, 'QQ11', 'The bubble will pop. LLMs will still be a thing, but most of the startups will disappear. Enshittification will begin and we will start to have to pay more for tokens or set up our own infrastructure. LLMs will incrementally improve, but they will reach a plateau. People will lose interest in low-effort "AI slop," but good AI content will continue to exist. People will start valuing concise and to-the-point communication over the flowery language that AI can produce.', 'The bubble will pop, startups will disappear, enshittification, LLMs will reach a plateau', 'forecast_plateau'),
(4, 'QQ0', '3 times a week', '3 times a week', 'use_moderately'),
(4, 'QQ1', 'I use as an alternative to Google', 'alternative to Google', 'partial_integration'),
(4, 'QQ2', 'I use as an alternative to Google. To understand concepts and learn about new frameworks', 'to understand concepts, learn about new frameworks', 'conceptual_use'),
(4, 'QQ3', 'I mainly use it for small scripting and not production code', 'for small scripting', 'scope_snippet'),
(4, 'QQ4', 'Faster researching unknown concepts', 'Faster researching', 'changes_speed_improvement'),
(4, 'QQ5', 'Never', 'Never', 'mundane_tasks_never'),
(4, 'QQ6', 'Faster prototyping to get started on new scripts', 'Faster prototyping', 'prototyping_use'),
(4, 'QQ7', 'Faster prototyping to get started on new scripts', 'Faster prototyping', 'prototyping_use'),
(4, 'QQ8', 'Outdated information', 'Outdated information', 'knowledge_cutoff'),
(4, 'QQ9', 'No', 'No', 'no_errors'),
(4, 'QQ11', 'We will use it more and more for small tasks.', 'for small tasks', 'forecast_extension'),
(5, 'QQ0', 'Everyday', 'Everyday', 'use_daily'),
(5, 'QQ1', 'Not every. I have the option of using Copilot in VS Code and Git, but I just use the online chat version', 'Not very', 'partial_integration'),
(5, 'QQ2', 'Advanced research of coding documentation, error troubleshooting, quick bloat code, or one-time-use scripts', 'research of coding documentation, error troubleshooting, quick bloat code, one-time-use scripts', 'documentation_use'),
(5, 'QQ3', 'I read every line and correct it to fit our standards and ensure it’s as good as if I had written it myself', 'I correct it', 'scope_project'),
(5, 'QQ4', 'I save a lot of time when I don’t have to do long, time-consuming tasks that are simple but tedious to develop. It also helps with understanding poorly documented libraries', 'I save a lot of time, helps with understanding', 'changes_speed_improvement'),
(5, 'QQ5', 'For the examples mentioned, I don’t really use it for that', 'I don’t really use it', 'mundane_tasks_infrequent'),
(5, 'QQ6', 'I don’t have to know all the specific syntax for simple code; I just need to know in general what and how to do it', 'know in general what and how to do it', 'improved_context'),
(5, 'QQ7', 'For getting to know new libraries and frameworks, and writing one-time scripts', 'to know new libraries and frameworks, writing one-time script', 'learning_use'),
(5, 'QQ8', 'Often incorrect about what is implemented in libraries, requiring me to verify by deep diving into the code or documentation', 'incorrect what is implemented in libraries, requiring me to verify', 'knowledge_cutoff'),
(5, 'QQ9', 'I have encountered many errors it makes, but never any that have made it past PR', 'many errors', 'output_errors'),
(5, 'QQ10', 'More code context — being able to use my whole codebase as context without it being uploaded to a server', 'More code context', 'improved_context'),
(6, 'QQ0', 'Daily', 'Daily', 'use_daily'),
(6, 'QQ1', 'Somewhat, it’s a separate tool that I pull out when needed', 'Somewhat', 'no_integration'),
(6, 'QQ2', 'Writing boilerplate code or code where the context is easily given. Describing context can take longer than just doing the code myself. Providing an overview of large amounts of text to identify patterns or missed lines', 'Writing boilerplate code, providing an overview', 'scope_project'),
(6, 'QQ3', 'Developer discretion. You are responsible for what you put to review', 'Developer discretion', 'modified_use'),
(6, 'QQ4', 'Some parts are faster, and doing a proof of concept outside of current skills is very easy. This is useful for determining if the skill is worth learning for a case', 'parts are faster, is useful for determining if the skill is worth learning', 'changes_speed_improvement'),
(6, 'QQ5', 'Multiple times per day', 'Multiple times per day', 'mundane_tasks_always'),
(6, 'QQ6', 'Being able to do proof of concept faster. The final code always requires work, so the final product is not always faster', 'do proof of concept faster', 'speed_up_coding'),
(6, 'QQ7', 'When combining large amounts of semi-structured data', 'combining large semi-structured data', 'data_analysis_use'),
(6, 'QQ8', 'Very generic answers and a tendency to suggest solutions that a new programmer would do. Likely due to experienced developers’ code being locked within companies and unavailable for training', 'Very generic answers', 'output_errors'),
(6, 'QQ9', 'Often uses old versions of libraries', 'uses old versions of libraries', 'knowledge_cutoff'),
(6, 'QQ10', 'Better at seeking missing information rather than just proceeding', 'seeking missing information', 'smarter_ai'),
(6, 'QQ11', 'Improvement to all of the above', 'Improvement', 'forecast_smarter_ai'),
(7, 'QQ0', 'I use them for small scripts needed quickly, but this is maybe once a month', 'once a month', 'use_infrequent'),
(7, 'QQ1', 'I generally don''t have a workflow for using it', 'don''t have a workflow for using it', 'no_integration'),
(7, 'QQ2', 'I might use it to do translations, make up variable names, and produce quick scripts for handling data or simple procedures', 'to do translations, make up variable names, produce scripts', 'scope_snippet'),
(7, 'QQ3', 'I don''t really use it in my codebase; it’s more of a tool used on the side, but it could potentially create a draft for a function for me', 'I don''t really use it', 'conceptual_use'),
(7, 'QQ4', 'Not much. I basically use it like I used Stack Overflow, just quicker, and it can explain what it does, which is helpful when debugging the code it writes', 'helpful when debugging', 'changes_speed_improvement'),
(7, 'QQ5', 'Not that often, maybe once every two months', 'once every two months', 'mundane_tasks_infrequent'),
(7, 'QQ6', 'It can produce quick code for proof of concept or provide alternative solutions', 'produce quick code, provide alternative solutions', 'changes_speed_improvement'),
(7, 'QQ7', 'When I start using a new library (only if it is a well-documented library)', 'using a new library', 'learning_use'),
(7, 'QQ8', 'That it often guesses and makes things up if the underlying training material is bad or the problem is unique', 'makes things up', 'output_errors'),
(7, 'QQ9', 'I have tried to use it for an RFID protocol called LLRP, which is poorly documented, and when it did not work, the model just made up functions that did not exist — and it did this very confidently. The biggest issue is if you just believe everything it says', 'The issue is if you believe everything it says', 'output_errors'),
(8, 'QQ0', 'I use LLM tools almost daily for my productivity. Helps me in debugging my code and feels like someone is working alongside me', 'almost daily', 'use_daily'),
(8, 'QQ1', 'I often use them during development tasks like debugging, writing test cases, and exploring new solutions', 'debugging, writing test cases, exploring new solutions', 'moderate_integration'),
(8, 'QQ2', 'Daily basis', 'Daily', 'scope_project, scope_snippet, scope_module'),
(8, 'QQ3', 'I get some boilerplate code and edit it based on the requirements of my design', 'get boilerplate code and edit it', 'code_review'),
(8, 'QQ4', 'It helps me by working alongside me, assisting in remembering certain responses required later in my code', 'assisting in remembering certain responses', 'code_review'),
(8, 'QQ5', 'I mostly use it for debugging my code changes', 'for debugging', 'mundane_tasks_frequent'),
(8, 'QQ6', 'Gives sample design workflows that are very useful to kickstart development instead of manually designing solutions', 'Gives sample design workflows', 'planning_use'),
(8, 'QQ7', 'When faced with bugs', 'with bugs', 'bug_fixing'),
(8, 'QQ8', 'Repetitive responses and sometimes not replying based on what is asked', 'Repetitive responses', 'output_errors'),
(8, 'QQ9', 'Yes, even though I use their responses, I use them as references and create my own from them', 'Yes', 'manual_intervention'),
(8, 'QQ10', 'Can integrate them into IDEs and make them more flexible', 'integrate them, make them more flexible', 'better_integration'),
(8, 'QQ11', 'Assisting humans in their tasks', 'Assisting', 'forecast_smarter_ai');

INSERT INTO "public"."questions" ("question_id", "question_text") VALUES
('QQ0', 'How frequently do you use LLM-based tools for software development?'),
('QQ1', 'How integrated are these tools into your current workflow? '),
('QQ10', 'What features or improvements would you like to see in future LLM tools?'),
('QQ11', 'How do you imagine AI tools evolving in your field in the next few years?'),
('QQ2', 'Describe how you typically use LLMs in your daily development tasks.'),
('QQ3', 'How do you combine LLM-generated code with your existing codebase?'),
('QQ4', 'In what ways have LLMs changed your development workflow?'),
('QQ5', 'How often do you use LLMs in order to speed up otherwise mundane tasks in your development workflow? (i.e. name refactoring, comment removal, class generation, etc…)'),
('QQ6', 'What benefits have you experienced from using LLMs during your development workflow? '),
('QQ7', 'In what situations do you find them most helpful?'),
('QQ8', 'What challenges or frustrations have you faced when using LLMs?'),
('QQ9', 'Have you encountered errors or issues caused by these tools? If so, describe these challenges.');

INSERT INTO "public"."participants" ("participant_id", "participant_country", "participant_position", "participant_experience") VALUES
(1, 'Portugal', 'Software Engineer', '0-1 year'),
(2, 'Portugal', 'Software Developer', '0-1 year'),
(3, 'Denmark', 'Software Engineer', '5-10 years'),
(4, 'Denmark', 'Software Engineer', '2-5 years'),
(5, 'Denmark', 'Software Developer', '2-5 years'),
(6, 'Denmark', 'Software Engineer', '2-5 years'),
(7, 'Denmark', 'Software Engineer', '2-5 years'),
(8, 'India', 'Software Developer', '1-2 years'),
(9, 'Portugal', 'Software Developer', '0-1 year'),
(10, 'Portugal', 'Software Developer', '2-5 years'),
(11, 'Portugal', 'Software Engineer', '2-5 years'),
(12, 'Portugal', 'Software Developer', '1-2 years'),
(13, 'Portugal', 'Software Developer', '1-2 years'),
(14, 'Portugal', 'Software Developer', '10+ years'),
(15, 'Portugal', 'Software Developer', '0-1 year'),
(16, 'Denmark', 'Software Developer', '2-5 years'),
(17, 'Portugal', 'Software Engineer', '1-2 years'),
(18, 'United States', 'Software Engineer', '1-2 years'),
(19, 'Portugal', 'Software Developer', '1-2 years'),
(20, 'Portugal', 'Software Architect', '10+ years'),
(21, 'United States', 'Software Engineer', '0-1 year'),
(22, 'Greece', 'Software Engineer', '10+ years'),
(23, 'Greece', 'Software Developer', '10+ years');

INSERT INTO "public"."descriptive_codes" ("category_id", "category_plain_text", "category_description") VALUES
('use_infrequent', 'Infrequent Use', 'The participant uses LLM-based tools for SWE in a sporadic or infrequent way.'),
('use_frequent', 'Frequent Use', 'The participant uses LLM-based tools for SWE frequently but still somewhat sporadically.'),
('use_very_frequent', 'Very Frequent Use', 'The participant uses LLM-based tools for SWE very frequently or almost daily'),
('use_daily', 'Daily Use', 'The participant uses LLM-based tools for SWE every day'),
('no_integration', 'No Integration', 'Tools are rarely or never integrated; the user must manually apply them.'),
('partial_integration', 'Partial Integration', 'Tools are used for specific tasks but require some effort to access or apply.'),
('moderate_integration', 'Moderate Integration', 'Tools are regularly used and somewhat embedded, but not fully seamless.'),
('full_integration', 'Full Integration', 'Tools are fully embedded; the user can use them continuously with minimal extra effort.'),
('scope_snippet', 'Snippet-Level Responsibility', 'The participant uses LLMs only for small pieces of code or isolated tasks.'),
('scope_module', 'Module-Level Responsibility', 'The participant uses LLMs for larger portions of code, modules, or functional components.'),
('scope_project', 'Project-Level Responsibility', 'The participant uses LLMs for entire projects, end-to-end tasks, or full implementations.'),
('code_review', 'Code Review', 'The participant uses LLMs in their development workflow to aid the review and refactoring of coding artifacts'),
('research', 'Research and General Searching', 'The participant uses LLMs in their development workflow as an aid for research and searching new concepts or information.'),
('bug_fixing', 'Bug Fixing', 'The participant reports using LLMs to fix bugs in their codebase or software artifacts.'),
('conceptual_use', 'Conceptual Use', 'The participant uses LLM outputs primarily for inspiration, brainstorming, or understanding concepts, not for direct implementation.'),
('learning_use', 'Learning Use', 'The participant uses LLM outputs to study examples, learn syntax, or understand new programming paradigms or techniques.'),
('planning_use', 'Planning Use', 'The participant uses LLM tools for planning, design, or outlining tasks rather than producing executable code or direct artifacts.'),
('data_analysis_use', 'Data Analysis Use', 'The participant uses LLMs to analyze data, generate insights, or assist in interpreting datasets within their development workflow.'),
('documentation_use', 'Documentation Use', 'The participant uses LLMs primarily to generate or refine documentation, comments, or reports related to their projects.'),
('prototyping_use', 'Prototyping Use', 'The participant uses LLMs to rapidly create prototypes, proof-of-concepts, or experimental implementations to test ideas.'),
('direct_use', 'Direct Use', 'The participant directly copies or incorporates LLM-generated code or text into their own work with minimal modification.'),
('modified_use', 'Modified Use', 'The participant adapts, edits, or refactors LLM-generated code before integrating it into their own artifacts.'),
('combining_reference', 'Output used as Reference', 'The participant uses LLM code as a reference to develop their own artifacts, but does not report directly importing it or combining it.'),
('improved_documentation', 'Improved Documentation Quality', 'The participant reports that using LLMs has led to clearer, more accurate, and higher-quality documentation, comments, or reports.'),
('improved_code_quality', 'Improved Code Quality', 'The participant reports that using LLMs has led to higher quality code, with fewer bugs, better structure, or improved maintainability.'),
('changes_speed_improvement', 'Faster Development Speed', 'The participant reports LLMs increasing the speed at which development is conducted or in other words, overall workflow time shortening.'),
('mundane_tasks_never', 'Never Used for Mundane Tasks', 'The participant reports never using LLMs to speed up mundane development tasks like name refactoring, comment removal or class generation'),
('mundane_tasks_infrequent', 'Infrequently Used for Mundane Tasks', 'The participant reports infrequently using LLMs to speed up mundane development tasks like name refactoring, comment removal or class generation'),
('mundane_tasks_frequent', 'Frequently Used for Mundane Tasks', 'The participant reports frequently using LLMs to speed up mundane development tasks like name refactoring, comment removal, or class generation.'),
('mundane_tasks_always', 'Always Used for Mundane Tasks', 'The participant reports consistently and habitually using LLMs to handle mundane development tasks like name refactoring, comment removal, or class generation.'),
('knowledge_cutoff', 'Outdated Knowledge Cutoff', 'The participant reports that LLMs produce outdated code or information due to their fixed knowledge cutoff date.'),
('query_time_consuming', 'Time-Consuming Querying', 'The participant reports that formulating queries and interacting with LLMs can be time-consuming or slow down their workflow.'),
('small_memory_context', 'Small Memory Context', 'The participant reports that LLMs have a short context window for memory, in other words cannot memorize enough information'),
('output_errors', 'Frequent Output Errors', 'The participant reports that LLM outputs frequently contain errors.'),
('manual_intervention', 'Output often requires Manual Intervention', 'The participant reports that LLM output often requires manual intervention'),
('poor_integration', 'Poor Integration', 'The participant reports that LLMs are difficult to integrate into their workflow or project environment, causing extra effort or disruption.'),
('high_computation_cost', 'High Computational Costs', 'The participant reports that using LLMs incurs high computational or resource costs, making them expensive or slow to use.'),
('llm_intervention', 'Output often requires LLM Sub-Query Intervention', 'The participant reports that LLM output often requires a sub query to be made in order to intervene in it.'),
('automatic_error_detection', 'Automatic Error Detection', 'The participant reports wishing LLMs possessed the capability to automatically detect errors in software artifacts.'),
('improved_context', 'Expectation of Larger Context Window', 'The participant wishes LLMs could handle larger context windows, allowing them to understand and process more information at once.'),
('better_integration', 'Better Integration', 'The participant wishes LLMs could integrate more deeply with their actual project files, beyond isolated code snippets.'),
('certainty_indicators', 'Confidence and Uncertainty Indicators', 'The participant wishes LLMs provided clearer confidence signals or warnings when outputs may be uncertain, to reduce mistakes.'),
('lower_computation_cost', 'Lower Computational Costs', 'The participant wishes LLMs could operate with reduced computational resources, making them faster and less expensive to use.'),
('smarter_ai', 'Expectation of Smarter AI', 'The participant wishes LLMs were generally smarter, with improved reasoning, problem-solving, and understanding capabilities.'),
('forecast_extension', 'Evolving as an Extension', 'The participant forecasts LLMs evolving as a extensions, add-ons or plugins.'),
('forecast_knowledge', 'Expectation of Updated Knowledge', 'The participant expects that LLMs will have more current or up-to-date knowledge in the future.'),
('forecast_integration', 'Expectation of Better Integration', 'The participant expects that LLMs will be better integrated into workflows and tools in the future.'),
('forecast_plateau', 'Expectation of AI Plateau', 'The participant expects that AI tools will reach a performance or capability plateau and show limited improvement in the future.'),
('forecast_smarter_ai', 'Expectation of Smarter AI', 'The participant expects that LLMs will become generally smarter in the future, with improved reasoning, problem-solving, and understanding capabilities.'),
('code_generation_from_requirements', 'Code Generation from Requirements', 'The participant reports using LLMs to generate code from pre-defined requirements.'),
('improved_workflow', 'Improved Workflow', 'The participant reports that using LLMs has improved their overall development workflow, including productivity, organization, or learning outcomes.'),
('use_moderately', 'Moderate Use', 'The participant uses LLM-based tools for software engineering a few times per week or on a moderately regular basis.'),
('no_errors', 'No Errors Reported', 'The participant reports not experiencing notable errors or problems when using LLM-generated outputs.'),
('speed_up_coding', 'Speed Up Coding', 'The participant reports that LLMs specifically make writing or prototyping code faster.'),
('more_usage', 'Expectation of Increased Usage', 'The participant expects that their use of LLM-based tools will increase over time or expand into more tasks.'),
('knowledge_update', 'Updated Knowledge Base', 'The participant expresses a desire or expectation that LLMs will have a more up-to-date or frequently refreshed knowledge base.'),
('N/A', 'Not Applicable', 'Used when the participant response does not provide a meaningful descriptive code or the question does not apply to them.');